{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42643865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Function to read and preprocess images and labels\n",
    "def preprocess_data(data_dir, labels_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(labels_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            label_file = os.path.join(labels_dir, filename)\n",
    "            with open(label_file, 'r') as file:\n",
    "                for line in file:\n",
    "                    line = line.strip().split()\n",
    "                    image_path = os.path.join(data_dir, line[0])\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.resize(image, (224, 224))  # Resize images to 224x224\n",
    "                    label = [float(x) for x in line[1:]]   # Convert label coordinates to float\n",
    "                    labels.append(label)\n",
    "                    images.append(image)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Load data directories\n",
    "train_images_dir = r'C:\\Users\\iamak\\OneDrive\\Documents\\GCET\\IPBL\\train\\images'\n",
    "train_labels_dir = r'C:\\Users\\iamak\\OneDrive\\Documents\\GCET\\IPBL\\train\\labels'\n",
    "test_images_dir = r'C:\\Users\\iamak\\OneDrive\\Documents\\GCET\\IPBL\\test\\images'\n",
    "test_labels_dir = r'C:\\Users\\iamak\\OneDrive\\Documents\\GCET\\IPBL\\test\\labels'\n",
    "val_images_dir = r'C:\\Users\\iamak\\OneDrive\\Documents\\GCET\\IPBL\\valid\\images'\n",
    "val_labels_dir =  r'C:\\Users\\iamak\\OneDrive\\Documents\\GCET\\IPBL\\valid\\labels'\n",
    "\n",
    "# Preprocess data\n",
    "train_images, train_labels = preprocess_data(train_images_dir, train_labels_dir)\n",
    "test_images, test_labels = preprocess_data(test_images_dir, test_labels_dir)\n",
    "val_images, val_labels = preprocess_data(val_images_dir, val_labels_dir)\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define models\n",
    "def build_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_resnet_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_vgg_model():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile models\n",
    "cnn_model = build_cnn_model()\n",
    "resnet_model = build_resnet_model()\n",
    "vgg_model = build_vgg_model()\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train models\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "cnn_history = cnn_model.fit(train_datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "                            steps_per_epoch=len(train_images) / batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=val_datagen.flow(val_images, val_labels, batch_size=batch_size),\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "resnet_history = resnet_model.fit(train_datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "                                  steps_per_epoch=len(train_images) / batch_size,\n",
    "                                  epochs=epochs,\n",
    "                                  validation_data=val_datagen.flow(val_images, val_labels, batch_size=batch_size),\n",
    "                                  callbacks=[early_stopping])\n",
    "\n",
    "vgg_history = vgg_model.fit(train_datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "                            steps_per_epoch=len(train_images) / batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=val_datagen.flow(val_images, val_labels, batch_size=batch_size),\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate models\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(test_images, test_labels)\n",
    "resnet_loss, resnet_accuracy = resnet_model.evaluate(test_images, test_labels)\n",
    "vgg_loss, vgg_accuracy = vgg_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"CNN Test Accuracy:\", cnn_accuracy)\n",
    "print(\"ResNet Test Accuracy:\", resnet_accuracy)\n",
    "print(\"VGG Test Accuracy:\", vgg_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
